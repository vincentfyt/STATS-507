{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from IPython.core.display import display, HTML\n",
    "import random\n",
    "from timeit import Timer\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Question 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "#op = []\n",
    "#for m in range(len(sample_list)):\n",
    " #   li = [sample_list[m]]\n",
    "  #      for n in range(len(sample_list)):\n",
    "   #         if (sample_list[m][0] == sample_list[n][0] and\n",
    "    #                sample_list[m][3] != sample_list[n][3]):\n",
    "     #           li.append(sample_list[n])\n",
    "      #  op.append(sorted(li, key=lambda dd: dd[3], reverse=True)[0])\n",
    "#res = list(set(op))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part a\n",
    "######  We try to find out all tuples in a list with the same first element but different third elements. Then we choose the tuple with the third larger element and put with unselected tuples in the original list in to a new list. The function returns a new list of tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part b\n",
    "##### It uses nested loops for finishing the comparing and selecting tuples. Lots of '[]' with different indexes makes the function not easy to read. Meanwhile, it creates two list as middle step to store and compare data, therefore the exeution time and RAM usage might be high. I think I can try to improve this snippet by using dictionaries instead of list, using list comprehension instead of for loops, and creating as few as intermediate variables for storing and comparing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate random tuples with size k\n",
    "def randomtuple(n,k,a,b):\n",
    "    low = int(a)\n",
    "    high = int(b)\n",
    "    k = int(k)\n",
    "# we want to make sure that the tuple is in a ascending order, otherwise print error message instead.\n",
    "    if low<= high:\n",
    "        l=[(list(np.random.randint(low,high,size = k))) for i in range(n)]\n",
    "        return l\n",
    "    else:\n",
    "        print(\"error message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[[5, 2, 8], [9, 8, 1], [8, 4, 2], [9, 0, 6], [9, 0, 7]]\n"
     ]
    }
   ],
   "source": [
    "# test the output category \n",
    "type(randomtuple(5, 3, -1, 10))\n",
    "\n",
    "x = type(randomtuple(5, 3, -1, 10))\n",
    "assert x == type([1]),\"correct\"\n",
    "print(type(randomtuple(5, 3, -1, 10)))\n",
    "print(randomtuple(5, 3, -1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2), (1, 9, 8)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list = [(1, 3, 5),(0,1,2),(1,9,8)]\n",
    "\n",
    "def function1(samplelist,index2):\n",
    "    samplelist = list()\n",
    "    index = 0\n",
    "    op = [] \n",
    "    for m in range(len(sample_list)):\n",
    "        li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][index] == sample_list[n][index] and\n",
    "                sample_list[m][index2] != sample_list[n][index2]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[index2], reverse=True)[0])\n",
    "    res = list(set(op))\n",
    "    return res\n",
    "function1(sample_list,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2), (1, 9, 8)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def improvedfunction(samplelist,index):\n",
    "    sample_list.sort()\n",
    "    index1 = index - len(samplelist[0])\n",
    "    index2 = 0\n",
    "    a = [max(l, key=lambda x: x[index1]) for _, l in groupby(sample_list, key=lambda x: x[index2])]\n",
    "    return a\n",
    "improvedfunction(sample_list,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 9, 8), (0, 1, 2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list = [(1, 3, 5),(0,1,2),(1,9,8)]\n",
    "\n",
    "def dictmethod(d,index):\n",
    "    index = len(sample_list[1])-1\n",
    "    dictionary1 = defaultdict(list)\n",
    "    for i in sample_list:\n",
    "        dictionary1[i[0]].append(i)\n",
    "        res = [max(val, key=lambda x: x[index]) for val in dictionary1.values()]\n",
    "    return res\n",
    "\n",
    "dictmethod(sample_list,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>function1</th>\n",
       "      <th>improvedfunction</th>\n",
       "      <th>dictmethod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  function1  improvedfunction  dictmethod\n",
       "0  1        5.9               3.1         5.0\n",
       "1  1        5.4               2.9         4.9\n",
       "2  1        6.5               2.6         4.9\n",
       "0  2        5.7               5.7         4.3\n",
       "1  2        5.4               2.4         4.2\n",
       "2  2        5.1               2.4         4.2\n",
       "0  3        9.7               2.7         4.4\n",
       "1  3        5.4               4.8         4.3\n",
       "2  3        5.2               2.4         4.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create the range for question 1 function\n",
    "low = random.sample(range(10,35),3)\n",
    "high = random.sample(range(50,100),3)\n",
    "\n",
    "# generate tuples with random numbers\n",
    "sample1 = randomtuple(10,3,low[0],high[0])\n",
    "sample2 = randomtuple(10,3,low[1],high[1])\n",
    "sample3 = randomtuple(10,3,low[2],high[2])\n",
    "\n",
    "sample = [sample1,sample2,sample3]\n",
    "\n",
    "\n",
    "## create a loop for running three functions and store the execution time\n",
    "res = defaultdict(list)\n",
    "n_seq = [1, 1, 1]\n",
    "res['n'] = n_seq\n",
    "for f in (function1,improvedfunction,dictmethod):\n",
    "    for n in n_seq:\n",
    "        t = Timer(\"f(a,b)\", globals={\"f\": f, \"a\": sample[0],\"b\":2 })\n",
    "        # find out the median time and store it as the variable for table\n",
    "        m = np.median([t.timeit(1) for i in range(3)]) \n",
    "        res[f.__name__].append(round(m * 1e6, 1))\n",
    "\n",
    "\n",
    "res2 = defaultdict(list)\n",
    "n_seq2 = [2, 2, 2]\n",
    "res2['n'] = n_seq2\n",
    "for f in (function1,improvedfunction,dictmethod):\n",
    "    for n in n_seq:\n",
    "        t = Timer(\"f(a,b)\", globals={\"f\": f, \"a\": sample[1],\"b\":2 })\n",
    "        m = np.median([t.timeit(1) for i in range(3)]) \n",
    "        res2[f.__name__].append(round(m * 1e6, 1))\n",
    "\n",
    "res3 = defaultdict(list)\n",
    "n_seq3 = [3, 3, 3]\n",
    "res3['n'] = n_seq3\n",
    "for f in (function1,improvedfunction,dictmethod):\n",
    "    for n in n_seq:\n",
    "        t = Timer(\"f(a,b)\", globals={\"f\": f, \"a\": sample[2],\"b\":2 })\n",
    "        m = np.median([t.timeit(1) for i in range(3)]) \n",
    "        res3[f.__name__].append(round(m * 1e6, 1))\n",
    "df1 = pd.DataFrame(res)\n",
    "df2 = pd.DataFrame(res2)\n",
    "df3 = pd.DataFrame(res3)\n",
    "# merge all seperate df into a comprehensive one\n",
    "newdf = pd.concat([df1,df2,df3])\n",
    "display(newdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>interview way</th>\n",
       "      <th>variance pseudo</th>\n",
       "      <th>variance estimation</th>\n",
       "      <th>mec interview weight</th>\n",
       "      <th>intverview weight</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62161</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>104236.582554</td>\n",
       "      <td>102641.406474</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62162</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>16116.354010</td>\n",
       "      <td>15457.736897</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62163</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7869.485117</td>\n",
       "      <td>7397.684828</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62164</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>127965.226204</td>\n",
       "      <td>127351.373299</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62165</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>13384.042162</td>\n",
       "      <td>12209.744980</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62166</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>64068.123183</td>\n",
       "      <td>60593.636684</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62167</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5303.683185</td>\n",
       "      <td>5024.464768</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62168</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6245.043868</td>\n",
       "      <td>5897.024603</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62169</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14783.600953</td>\n",
       "      <td>14391.778470</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62170</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>8291.636582</td>\n",
       "      <td>7794.526990</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  age  race education marital  interview way  variance pseudo  \\\n",
       "0  62161   22     3       3.0     5.0            2.0              1.0   \n",
       "1  62162    3     1       NaN     NaN            2.0              3.0   \n",
       "2  62163   14     6       NaN     NaN            2.0              3.0   \n",
       "3  62164   44     3       4.0     1.0            2.0              1.0   \n",
       "4  62165   14     4       NaN     NaN            2.0              2.0   \n",
       "5  62166    9     3       NaN     NaN            2.0              1.0   \n",
       "6  62167    0     6       NaN     NaN            2.0              2.0   \n",
       "7  62168    6     7       NaN     NaN            2.0              2.0   \n",
       "8  62169   21     6       3.0     5.0            2.0              1.0   \n",
       "9  62170   15     7       NaN     NaN            2.0              3.0   \n",
       "\n",
       "   variance estimation  mec interview weight  intverview weight       year  \n",
       "0                 91.0         104236.582554      102641.406474  2011-2012  \n",
       "1                 92.0          16116.354010       15457.736897  2011-2012  \n",
       "2                 90.0           7869.485117        7397.684828  2011-2012  \n",
       "3                 94.0         127965.226204      127351.373299  2011-2012  \n",
       "4                 90.0          13384.042162       12209.744980  2011-2012  \n",
       "5                 91.0          64068.123183       60593.636684  2011-2012  \n",
       "6                 92.0           5303.683185        5024.464768  2011-2012  \n",
       "7                103.0           6245.043868        5897.024603  2011-2012  \n",
       "8                 92.0          14783.600953       14391.778470  2011-2012  \n",
       "9                 91.0           8291.636582        7794.526990  2011-2012  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>interview way</th>\n",
       "      <th>variance pseudo</th>\n",
       "      <th>variance estimation</th>\n",
       "      <th>mec interview weight</th>\n",
       "      <th>intverview weight</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62161</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>104236.582554</td>\n",
       "      <td>102641.406474</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62162</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>16116.354010</td>\n",
       "      <td>15457.736897</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62163</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7869.485117</td>\n",
       "      <td>7397.684828</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62164</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>127965.226204</td>\n",
       "      <td>127351.373299</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62165</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>13384.042162</td>\n",
       "      <td>12209.744980</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9249</th>\n",
       "      <td>102952</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18338.711104</td>\n",
       "      <td>16896.276203</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>102953</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>63661.951573</td>\n",
       "      <td>61630.380013</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9251</th>\n",
       "      <td>102954</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>17694.783346</td>\n",
       "      <td>17160.895269</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9252</th>\n",
       "      <td>102955</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14871.839636</td>\n",
       "      <td>14238.445922</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>102956</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>39426.299948</td>\n",
       "      <td>38645.740291</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39156 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  age  race education marital  interview way  variance pseudo  \\\n",
       "0      62161   22     3       3.0     5.0            2.0              1.0   \n",
       "1      62162    3     1       NaN     NaN            2.0              3.0   \n",
       "2      62163   14     6       NaN     NaN            2.0              3.0   \n",
       "3      62164   44     3       4.0     1.0            2.0              1.0   \n",
       "4      62165   14     4       NaN     NaN            2.0              2.0   \n",
       "...      ...  ...   ...       ...     ...            ...              ...   \n",
       "9249  102952   70     6       3.0     1.0            2.0              2.0   \n",
       "9250  102953   42     1       3.0     4.0            2.0              2.0   \n",
       "9251  102954   41     4       5.0     5.0            2.0              1.0   \n",
       "9252  102955   14     4       NaN     NaN            2.0              1.0   \n",
       "9253  102956   38     3       4.0     3.0            2.0              1.0   \n",
       "\n",
       "      variance estimation  mec interview weight  intverview weight       year  \n",
       "0                    91.0         104236.582554      102641.406474  2011-2012  \n",
       "1                    92.0          16116.354010       15457.736897  2011-2012  \n",
       "2                    90.0           7869.485117        7397.684828  2011-2012  \n",
       "3                    94.0         127965.226204      127351.373299  2011-2012  \n",
       "4                    90.0          13384.042162       12209.744980  2011-2012  \n",
       "...                   ...                   ...                ...        ...  \n",
       "9249                138.0          18338.711104       16896.276203  2017-2018  \n",
       "9250                137.0          63661.951573       61630.380013  2017-2018  \n",
       "9251                144.0          17694.783346       17160.895269  2017-2018  \n",
       "9252                136.0          14871.839636       14238.445922  2017-2018  \n",
       "9253                142.0          39426.299948       38645.740291  2017-2018  \n",
       "\n",
       "[39156 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read files\n",
    "df2011 = pd.read_sas(\"C:/Users/fengy/Desktop/stats 507/hw2/DEMO2011-2012.XPT\")\n",
    "# add columns to a single dataframe\n",
    "df2011['year'] = \"2011-2012\"\n",
    "# read file and import it as df\n",
    "df2013 = pd.read_sas(\"C:/Users/fengy/Desktop/stats 507/hw2/DEMO2013-2014.XPT\")\n",
    "# add columns to a single dataframe\n",
    "df2013['year'] = \"2013-2014\"\n",
    "# read file and import it as df\n",
    "df2015 = pd.read_sas(\"C:/Users/fengy/Desktop/stats 507/hw2/DEMO2015-2016.XPT\")\n",
    "# add columns to a single dataframe\n",
    "df2015['year'] = \"2015-2016\"\n",
    "# read file and import it as df\n",
    "df2017 = pd.read_sas(\"C:/Users/fengy/Desktop/stats 507/hw2/DEMO2017-2018.XPT\")\n",
    "# add columns to a single dataframe\n",
    "df2017['year'] = \"2017-2018\"\n",
    "# merge seperate dataframes into one\n",
    "mergedf = pd.concat([df2011, df2013,df2015,df2017])\n",
    "# select columns from a dataframe\n",
    "mydf = pd.DataFrame(mergedf[[\"SEQN\",\"RIDAGEYR\",\"RIDRETH3\",\"DMDEDUC2\",\"DMDMARTL\",\n",
    "                  \"RIDSTATR\", \"SDMVPSU\", \"SDMVSTRA\", \"WTMEC2YR\", \"WTINT2YR\",\"year\"]])\n",
    "# change the column name\n",
    "mydf = mydf.rename({'SEQN': 'id', 'RIDAGEYR': 'age',\n",
    "                'RIDRETH3':'race', 'DMDEDUC2':'education',\n",
    "                 'DMDMARTL':'marital', 'RIDSTATR':'interview way',\n",
    "                 \"SDMVPSU\": \"variance pseudo\",\n",
    "                 \"SDMVSTRA\":\"variance estimation\",\n",
    "                 \"WTMEC2YR\":\"mec interview weight\",\n",
    "                 \"WTINT2YR\":\"intverview weight\",\n",
    "                 \"year\":\"year\"\n",
    "                }, axis='columns')\n",
    "# change the column data types\n",
    "mydf = mydf.astype({\"id\": int, \"age\": int,\"race\":int, \n",
    "                    \"education\":\"category\",\n",
    "                    \"marital\":'category'})\n",
    "display(mydf.head(10))\n",
    "# display the dataframe\n",
    "display(mydf)\n",
    "# #### part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\pandas\\io\\sas\\sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>01TC</th>\n",
       "      <th>02TC</th>\n",
       "      <th>03TC</th>\n",
       "      <th>04TC</th>\n",
       "      <th>05TC</th>\n",
       "      <th>06TC</th>\n",
       "      <th>07TC</th>\n",
       "      <th>08TC</th>\n",
       "      <th>...</th>\n",
       "      <th>23CTC</th>\n",
       "      <th>24CTC</th>\n",
       "      <th>25CTC</th>\n",
       "      <th>26CTC</th>\n",
       "      <th>27CTC</th>\n",
       "      <th>28CTC</th>\n",
       "      <th>29CTC</th>\n",
       "      <th>30CTC</th>\n",
       "      <th>31CTC</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Y'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>71912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8952</th>\n",
       "      <td>71913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>71914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Y'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Y'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>71915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8955</th>\n",
       "      <td>71916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36499 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  status  01TC  02TC  03TC  04TC  05TC  06TC  07TC  08TC  ...  \\\n",
       "0     62161     1.0   4.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0  ...   \n",
       "1     62162     1.0   4.0   4.0   4.0   1.0   1.0   1.0   1.0   1.0  ...   \n",
       "2     62163     1.0   4.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0  ...   \n",
       "3     62164     1.0   4.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0  ...   \n",
       "4     62165     1.0   4.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0  ...   \n",
       "...     ...     ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "8951  71912     1.0   4.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0  ...   \n",
       "8952  71913     1.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0  ...   \n",
       "8953  71914     1.0   4.0   4.0   2.0   1.0   1.0   1.0   2.0   2.0  ...   \n",
       "8954  71915     1.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0  ...   \n",
       "8955  71916     1.0   4.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0  ...   \n",
       "\n",
       "      23CTC  24CTC  25CTC  26CTC  27CTC  28CTC  29CTC  30CTC  31CTC       year  \n",
       "0      b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'Z'   b'S'  2011-2012  \n",
       "1      b'D'   b'D'   b'D'   b'D'   b'D'   b'D'   b'D'   b'U'   b'U'  2011-2012  \n",
       "2      b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'Y'   b'S'  2011-2012  \n",
       "3      b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'Z'   b'Z'  2011-2012  \n",
       "4      b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'  2011-2012  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...        ...  \n",
       "8951   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'Z'   b'S'  2017-2018  \n",
       "8952   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'  2017-2018  \n",
       "8953   b'Y'   b'S'   b'S'   b'S'   b'Y'   b'D'   b'D'   b'S'   b'U'  2017-2018  \n",
       "8954   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'Z'   b'Z'  2017-2018  \n",
       "8955   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'S'   b'Z'   b'U'  2017-2018  \n",
       "\n",
       "[36499 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read dataframe,select required columns, add columns, and build it as a single df\n",
    "oral2011 = pd.read_sas(\"C:/Users/fengy/Desktop/stats 507/hw2(1)/OHXDEN2011-2012.XPT\")\n",
    "oral2011 =oral2011.loc[:,'SEQN':'OHX31CTC']\n",
    "oral2011.drop(['OHDEXSTS', 'OHXIMP'],inplace=True, axis=1)\n",
    "oral2011[\"year\"] = \"2011-2012\"\n",
    "\n",
    "\n",
    "# read dataframe,select required columns, add columns, and build it as a single df\n",
    "oral2013 = pd.read_sas(\"C:/Users/fengy/Desktop/stats 507/hw2(1)/OHXDEN2013-2014.XPT\")\n",
    "oral2013 =oral2013.loc[:, 'SEQN':'OHX31CTC']\n",
    "oral2013.drop(['OHDEXSTS', 'OHXIMP'], inplace=True, axis=1)\n",
    "oral2013[\"year\"] = \"2013-2014\"\n",
    "\n",
    "\n",
    "# read dataframe,select required columns, add columns, and build it as a single df\n",
    "oral2015 = pd.read_sas(\"C:/Users/fengy/Desktop/stats 507/hw2(1)/OHXDEN2015-2016.XPT\")\n",
    "oral2015 =oral2015.loc[:, 'SEQN':'OHX31CTC']\n",
    "oral2015.drop(['OHDEXSTS', 'OHXIMP'], inplace=True, axis=1)\n",
    "oral2015[\"year\"] = \"2015-2016\"\n",
    "\n",
    "\n",
    "# read dataframe,select required columns, add columns, and build it as a single df\n",
    "oral2017 = pd.read_sas(\"C:/Users/fengy/Desktop/stats 507/hw2(1)/OHXDEN2011-2012.XPT\")\n",
    "oral2017 =oral2017.loc[:,'SEQN':'OHX31CTC']\n",
    "oral2017.drop(['OHDEXSTS', 'OHXIMP'], inplace=True, axis=1)\n",
    "oral2017[\"year\"] = \"2017-2018\"\n",
    "\n",
    "# merge each sepearte df into one, change the datatype, and change the column name.\n",
    "partb = pd.concat([oral2011, oral2013,oral2015,oral2017])\n",
    "partb = partb.astype({\"SEQN\": int})\n",
    "partb = partb.rename({\"SEQN\": 'id', \"OHDDESTS\": 'status'},\n",
    "                   axis='columns')\n",
    "partb = partb.rename(columns=lambda x: x[3:])\n",
    "partb = partb.rename({'':'id', 'tus':'status','r':'year'},\n",
    "                     axis='columns')\n",
    "display(partb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "a = mydf['id']\n",
    "b = partb['id']\n",
    "# find out the cases shareing the same Id\n",
    "display(len(set(a).intersection(set(b))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
